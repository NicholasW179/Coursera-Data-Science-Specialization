This section contains the files for the third course getting and cleaning data. the codebook is as follows:

This code in run_analysis.r downloads the files from the internet, then uses regular expressions to pull the means and standard deviations.
Then it pulls out the features wanted, and combines them into both training and test data. Finally it merges the files into a combined data set.


#Dataset Information:#

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years.
Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist.
Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz.
The experiments have been video-recorded to label the data manually.
The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window).
The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity.
The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.


The following information is provided for each movement:


Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
Triaxial Angular velocity from the gyroscope.
A 561-feature vector with time and frequency domain variables.
Its activity label.
An identifier of the subject who carried out the experiment.

#DataSets# The following Datasets are included in the analysis:

features_info.txt': Shows information about the variables used on the feature vector.

'features.txt': List of all features.

'activity_labels.txt': Links the class labels with their activity name.

'train/X_train.txt': Training set.

'train/y_train.txt': Training labels.

'test/X_test.txt': Test set.

'test/y_test.txt': Test labels.

During the analysis the following are created:
tactivities: the activities in the training set
tsubjects: the subject numbers in the training set
train: initially the measurements, later combined with both tsubjects and tactivities 

test_activity: the activities in the test set
test_subject: the subject numbers in the test set
test: combined measurements with activities and subject numbers

combined: the full combination of train and test sets
The commands do the following:
1. Download the files and unzip them
2. Read in the appropriate datasets, and extract features wanted
3. Combine the appropriate datasets into one training and one test file
4. Merge the training and testing sets into one combined file.
5. Create a tidy, smaller dataset with just the means


Use of this dataset requires reference of the following publication:
Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz.
A Public Domain Dataset for Human Activity Recognition Using Smartphones. 
21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.
